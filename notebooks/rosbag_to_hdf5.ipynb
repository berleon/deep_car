{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import rosbag\n",
    "import rospy\n",
    "import numpy as np\n",
    "import ros_numpy as rosnp\n",
    "from sensor_msgs.msg import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from scipy.misc import imsave, imread\n",
    "import os\n",
    "from StringIO import StringIO\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from PIL import ImageDraw, ImageFont, ImageFilter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import h5py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosbag_fname = '../../deep_car_data/2017-05-31-14-20-54.bag'\n",
    "rosbag_name, _ = os.path.splitext(os.path.basename(rosbag_fname))\n",
    "\n",
    "data_dir = '../data'\n",
    "\n",
    "rosbag_fnames_to_convert = [\n",
    "    rosbag_fname\n",
    "]\n",
    "\n",
    "rescale_factor = 8\n",
    "tmp = os.path.abspath('../tmp/')\n",
    "if not os.path.exists(tmp):\n",
    "    os.makedirs(tmp)\n",
    "    \n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class topics:\n",
    "    image = \"/app/camera/rgb/image_raw/compressed\"\n",
    "    lights = \"/manual_control/lights\"\n",
    "    speed = \"/manual_control/speed\"\n",
    "    steering = \"/manual_control/steering\"\n",
    "    stop_start = \"/manual_control/stop_start\"\n",
    "    yaw = \"/model_car/yaw\"\n",
    "    twist = \"/motor_control/twist\" \n",
    "    odom = \"/odom\"\n",
    "    \n",
    "    labels = [speed, steering, yaw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ros_jpeg_to_numpy(msg):\n",
    "    if msg.format != 'rgb8; jpeg compressed bgr8':\n",
    "        raise Exception(\"Wrong format\")\n",
    "    return imread(StringIO(msg.data))\n",
    "\n",
    "def ros_jpeg_to_pil(msg):\n",
    "    if msg.format != 'rgb8; jpeg compressed bgr8':\n",
    "        raise Exception(\"Wrong format\")\n",
    "    return PIL.Image.open(StringIO(msg.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag(rosbag_fname)\n",
    "bag.get_start_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(t):\n",
    "    return (1-t)*bag.get_start_time() + t*bag.get_end_time()\n",
    "\n",
    "print(bag.get_start_time())\n",
    "print(get_time(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tti = bag.get_type_and_topic_info()\n",
    "\n",
    "fmt = \"{:40}| {:30}| {:<20}\"\n",
    "print(fmt.format(\"topic\", \"message type\", \"count\"))\n",
    "print(\"-\" * 80)\n",
    "for name, topic in sorted(tti.topics.items()):\n",
    "    print fmt.format(name, topic.msg_type, topic.message_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all messages for lables and convert them to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_data = {t: [] for t in topics.labels}\n",
    "times = {t: [] for t in topics.labels}\n",
    "def parse_msg(msg, msg_type):\n",
    "    \n",
    "    if msg_type in (\"std_msgs/Int16\", \"std_msgs/Float32\"):\n",
    "        return msg.data\n",
    "    elif msg_type == 'geometry_msgs/Twist':\n",
    "        return {\n",
    "            msg.linear.x,\n",
    "        }\n",
    "    else:\n",
    "        raise Exception('unknown')\n",
    "        \n",
    "for topic, msg, time in bag.read_messages(topics=topics.labels):\n",
    "    msg_type = tti.topics[topic].msg_type\n",
    "    data = parse_msg(msg, msg_type)\n",
    "    times[topic].append(time.to_sec())\n",
    "    topic_data[topic].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = {}\n",
    "for k, data in topic_data.items():\n",
    "    df[k] = pd.Series(data, index=pd.DatetimeIndex(pd.to_datetime(times[k], unit='s')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_df = df[topics.steering]\n",
    "yaw_df = df[topics.yaw]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "steering_df.plot(ax=ax, label='steering')\n",
    "ax.set_ylabel('steering')\n",
    "ax2 = ax.twinx()\n",
    "yaw_df.plot(ax=ax2, color='red', label='yaw')\n",
    "ax2.set_ylabel('yaw')\n",
    "plt.title(\"Connection between steering and yaw\")\n",
    "ax.legend(loc='upper left', frameon=True)\n",
    "ax2.legend(loc='upper right', frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df = df[topics.speed]\n",
    "speed_df.plot(kind='line', label='speed')\n",
    "plt.title(\"Speed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = tti.topics['/app/camera/rgb/image_raw/compressed'].frequency\n",
    "print(\"Frame rate is: {:.2f}\".format(frame_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save images as video\n",
    "img_fnames = []\n",
    "tmp_dir = tempfile.mkdtemp(dir=tmp)\n",
    "try:\n",
    "    for i, (topic, msg, time) in enumerate(tqdm(bag.read_messages(topics=[topics.image]))):\n",
    "        img_fname = os.path.join(tmp_dir, \"{:06d}.jpeg\".format(i))\n",
    "        with open(img_fname, 'wb') as f:\n",
    "            f.write(msg.data)\n",
    "        img_fnames.append(img_fname)\n",
    "\n",
    "    video = ImageSequenceClip(img_fnames, fps=frame_rate, with_mask=False)\n",
    "    video.write_videofile(rosbag_name + \".webm\",\n",
    "                          ffmpeg_params=['-b:v', '0', '-crf', '10'])\n",
    "finally:\n",
    "    shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a video with steering, speed, and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def command_at(df, time):\n",
    "    if type(time) == rospy.rostime.Time:\n",
    "        time = time.to_sec()\n",
    "    dt = pd.to_datetime(time, unit='s')\n",
    "    before = df[:dt]\n",
    "    if len(before) != 0:\n",
    "        return before[-1]\n",
    "    else:\n",
    "        return df[dt:][0]\n",
    "\n",
    "def image_draw_info(img, speed, steering, time, font=None):\n",
    "    if font is None:\n",
    "        fonts = matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "        mono_fonts = [f for f in fonts if \"mono\" in f.lower() and 'bold' in f.lower()]\n",
    "        mono_font = mono_fonts[0]\n",
    "        font = ImageFont.truetype(mono_font, 18)\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    draw.text((10, 450), time, fill=\"#ffffff\", font=font)\n",
    "    draw.text((10, 20), \"steering: {}\".format(steering), fill=\"#00ff00\", font=font)\n",
    "    angle = (steering) / 180. * np.pi\n",
    "    x = img.size[0] / 2\n",
    "    y = 100\n",
    "    draw.line([x, y, x +  60*np.cos(angle), y  - 60*np.sin(angle)], fill=\"#00ff00\", width=3)\n",
    "    draw.text((10, 50), \"speed: {}\".format(speed), fill='#ff0000', font=font)\n",
    "    del draw\n",
    "    \n",
    "img_fnames = []\n",
    "tmp_dir = tempfile.mkdtemp(dir=tmp)\n",
    "\n",
    "for i, (topic, msg, time) in enumerate(tqdm(\n",
    "    bag.read_messages(topics=topics.image, end_time=rospy.Time(get_time(0.5))))):\n",
    "    \n",
    "    img_fname = os.path.join(tmp_dir, \"{:06d}.png\".format(i))\n",
    "    img = ros_jpeg_to_numpy(msg)\n",
    "    \n",
    "    img = PIL.Image.fromarray(img)\n",
    "    for name, d in df.items():\n",
    "        value = command_at(d, time)\n",
    "        \n",
    "        if name == topics.steering:\n",
    "            steering = value\n",
    "        elif name == topics.speed:\n",
    "            speed = value\n",
    "    dtime = datetime.fromtimestamp(time.to_sec())\n",
    "    image_draw_info(img, speed, steering, dtime.isoformat())\n",
    "    img.save(img_fname)\n",
    "    del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video = ImageSequenceClip(tmp_dir, fps=frame_rate, with_mask=False)\n",
    "video.write_videofile(rosbag_name + \"_controls.webm\", ffmpeg_params=['-b:v', '0', '-crf', '20'])\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise rescaling of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_img(img):\n",
    "    blur = ImageFilter.GaussianBlur(radius=rescale_factor * 1./3)\n",
    "    return img.convert('L').filter(blur).resize(img_shape_pil, resample=PIL.Image.BILINEAR)\n",
    "    \n",
    "topic, msg, time = next(bag.read_messages(topics=topics.image))\n",
    "\n",
    "img = ros_jpeg_to_pil(msg)\n",
    "w, h = img.size\n",
    "# numpy it is h, w and in the PIL world w, h\n",
    "img_shape_pil = (w / rescale_factor, h / rescale_factor)\n",
    "img_shape = (h / rescale_factor, w / rescale_factor)\n",
    "print(\"rescaled image {}:\".format(img_shape))\n",
    "rescale_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hdf5 file and convert all rosbag files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_fname = os.path.join(data_dir, 'train.hdf5')\n",
    "if os.path.exists(h5_fname):\n",
    "    os.remove(h5_fname)\n",
    "h5 = h5py.File(h5_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 32\n",
    "h5.create_dataset('image', shape=(1, ) + img_shape, dtype='uint8',\n",
    "                  maxshape=(None,) + img_shape,\n",
    "                  chunks=(64,) + img_shape)\n",
    "h5.create_dataset('speed', shape=(1, 1), dtype='float32', \n",
    "                  maxshape=(None, 1), chunks=(chunk, 1))\n",
    "h5.create_dataset('steering', shape=(1, 1), dtype='float32', maxshape=(None, 1), chunks=(chunk, 1))\n",
    "h5.create_dataset('timestamp', shape=(1, 1), dtype='float64', maxshape=(None, 1), chunks=(chunk, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_norm = np.array([1 / 180. * np.pi, -np.pi/2])\n",
    "speed_norm = np.array([1 / 500., 0])\n",
    "h5['steering'].attrs['normalize'] = steering_norm\n",
    "h5['speed'].attrs['normalize'] = speed_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(normalize, value):\n",
    "    return np.dot(normalize, [value, 1])\n",
    "\n",
    "i = 0\n",
    "for fname in rosbag_fnames_to_convert:\n",
    "    bag = rosbag.Bag(rosbag_fname)\n",
    "\n",
    "    for topic, msg, time in tqdm(bag.read_messages(topics=topics.image)):\n",
    "        for dset in h5.values():\n",
    "            dset.resize(size=i+1, axis=0)\n",
    "\n",
    "        img = ros_jpeg_to_pil(msg)\n",
    "        h5['image'][i] = np.array(rescale_img(img))\n",
    "        h5['speed'][i] = normalize(speed_norm, command_at(speed_df, time))\n",
    "        h5['steering'][i] = normalize(steering_norm, command_at(steering_df, time))\n",
    "        h5['timestamp'][i] = time.to_sec()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:10}| {:10}| {:30}\".format(\"name\", \"dtype\", \"shape\"))\n",
    "print(\"-\" * 40)\n",
    "for name, dset in h5.items():\n",
    "    print(\"{:10}| {:10}| {:30}\".format(name, dset.dtype, dset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 100\n",
    "images = [h5['image'][i*step] for i in range(10)]\n",
    "PIL.Image.fromarray(np.concatenate(images, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
