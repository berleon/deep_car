{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import six\n",
    "from six.moves import range\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageOps\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.font_manager\n",
    "from PIL import ImageDraw, ImageFont, ImageFilter\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "model_dir = '../data/model'\n",
    "model_name = 'steering_mixture_prob'\n",
    "tmp_dir = '../tmp'\n",
    "\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "crop_size = (64, 48)\n",
    "\n",
    "h5_train = h5py.File(os.path.join(data_dir, 'train.hdf5'))\n",
    "h5_test = h5py.File(os.path.join(data_dir, 'test.hdf5'))\n",
    "\n",
    "\n",
    "delta_discretize_min = -36 - 4.5\n",
    "delta_discretize_max = 36 + 4.5\n",
    "delta_discretize_buckets = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(delta_discretize_max - delta_discretize_min) / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:10}| {:10}| {:30}\".format(\"name\", \"dtype\", \"shape\"))\n",
    "print(\"-\" * 40)\n",
    "for name, dset in h5_train.items():\n",
    "    print(\"{:10}| {:10}| {:30}\".format(name, str(dset.dtype), str(dset.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size=128, n_epoch=-1,\n",
    "                   steering_history=[-8, -4, -2, -1],\n",
    "                   delta_times=[0, 1, 2, 4, 8, 16],\n",
    "                   shuffle=True, train=True,\n",
    "                  ):\n",
    "    def get_steering(idx):\n",
    "        idx = clip(idx)\n",
    "        return np.array(steering[idx])\n",
    "                        \n",
    "    def clip(x):\n",
    "        return np.clip(x, 0, n-1)\n",
    "    \n",
    "    if train:\n",
    "        h5 = h5_train\n",
    "    else:\n",
    "        h5 = h5_test\n",
    "    steering = np.array(h5['steering'])\n",
    "        \n",
    "    n = len(h5['image'])\n",
    "    idx = np.arange(n)\n",
    "    n_batches = n // batch_size\n",
    "    if n_epoch == -1:\n",
    "        n_epoch = 1000000000\n",
    "        \n",
    "    for epoch in range(n_epoch):\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idx)\n",
    "        for b in range(0, n, batch_size):\n",
    "            batch_idx = np.sort(idx[b:b+batch_size])\n",
    "            s_m1 = get_steering(batch_idx - 1)\n",
    "            batch = {\n",
    "                'image': h5['image'][batch_idx, :, :],\n",
    "                'speed': h5['speed'][batch_idx, :],\n",
    "                'steering_abs': h5['steering'][batch_idx, :],\n",
    "            }\n",
    "            for t in delta_times:\n",
    "                batch['steering_delta_{:02d}'.format(t)] = get_steering(batch_idx + t) - s_m1\n",
    "                \n",
    "            for t in steering_history:\n",
    "                batch['steering_m{:02d}'.format(-t)] = get_steering(batch_idx + t)\n",
    "            \n",
    "            yield batch\n",
    "            \n",
    "batch = next(data_generator())\n",
    "for name, arr in sorted(batch.items()):\n",
    "    print(\"{:<17} | {:} \".format(name, arr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['image'].min(), batch['image'].max(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 10, figsize=(15, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_title(\"{:.1f}\".format(float(180 / np.pi * batch['steering_delta_00'][i])))\n",
    "    ax.imshow(batch['image'][i], cmap='gray')\n",
    "    ax.grid('off')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of seconds per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%timeit -n 3\n",
    "\n",
    "#for batch in data_generator(n_epoch=1):\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deltas = {key: [] for key in batch.keys() if 'delta' in key}\n",
    "\n",
    "for batch in data_generator(n_epoch=1):\n",
    "    for key, arr in batch.items():\n",
    "        if 'delta' in key:\n",
    "            deltas[key].append(arr)\n",
    "deltas = {k: np.concatenate(arrs).flatten() for k, arrs in deltas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "\n",
    "for ax, (key, delta) in zip(axes.flatten(), sorted(deltas.items())):\n",
    "    ax.hist(np.clip(180 / np.pi * delta, -45, 45), bins=30)\n",
    "    ax.set_title(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(data_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_img(img):\n",
    "    width, height = img.size\n",
    "    max_crop_left = img.size[0] - crop_size[0]\n",
    "    max_crop_upper = img.size[1] - crop_size[1]\n",
    "    left = np.random.choice(max_crop_left)\n",
    "    upper = np.random.choice(max_crop_upper)\n",
    "    img = img.crop([left, upper, left + crop_size[0], upper + crop_size[1]])\n",
    "                    #width - left, height - upper])\n",
    "    brightness = ImageEnhance.Brightness(img)\n",
    "\n",
    "    img = brightness.enhance(np.random.uniform(0.75, 2.5))\n",
    "    contrast = ImageEnhance.Contrast(img)\n",
    "    img = contrast.enhance(np.random.uniform(0.75, 2.5))\n",
    "    return img\n",
    "\n",
    "images = [PIL.Image.fromarray(x) for x in batch[\"image\"]]\n",
    "img = images[0]\n",
    "fig, axes = plt.subplots(4, 12, figsize=(20, 5))\n",
    "\n",
    "for ax in axes[:1].flat:\n",
    "    ax.imshow(np.array(img), cmap='gray', vmin=0, vmax=255)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "for ax in axes[1:].flat:\n",
    "    ax.imshow(np.array(augment_img(img)), cmap='gray', vmin=0, vmax=255)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(batch):\n",
    "    images = [PIL.Image.fromarray(x) for x in batch[\"image\"]]\n",
    "    images = [augment_img(img) for img in images]\n",
    "    batch_aug = {'image': np.stack([np.array(img) for img in images])}\n",
    "    for k, v in batch.items():\n",
    "        if k != 'image':\n",
    "            batch_aug[k] = v\n",
    "    return batch_aug\n",
    "\n",
    "batch_aug = augment_batch(batch)\n",
    "\n",
    "fig, axes = plt.subplots(3, 12, figsize=(15, 4))\n",
    "\n",
    "for ax, img, steering in zip(axes.flat, batch_aug['image'], batch_aug['steering_delta_00']):\n",
    "    ax.imshow((img), cmap='gray')\n",
    "    ax.set_title(\"{:}\".format(int(180*float(steering) / np.pi)))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_hist(batch):\n",
    "    steering = []\n",
    "    for key, arr in sorted(batch.items()):\n",
    "        if 'steering_m' in key:\n",
    "            steering.append(arr)\n",
    "    return np.concatenate(steering, axis=-1)\n",
    "\n",
    "def get_steering_delta(batch):\n",
    "    steering = []\n",
    "    for key, arr in sorted(batch.items()):\n",
    "        if 'steering_delta' in key:\n",
    "            steering.append(arr)\n",
    "    return np.concatenate(steering, axis=-1)\n",
    "\n",
    "get_steering_hist(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_int(y, n_buckets=180):\n",
    "    return (y * n_buckets).astype(np.int)\n",
    "\n",
    "def discretize(y, n_buckets, min, max):\n",
    "    y = np.clip(y, min, max)\n",
    "    y_norm = (y - min) / (max - min)\n",
    "    y_buckets = y_norm * n_buckets\n",
    "    y_disc = y_buckets.astype(np.int) \n",
    "    y_disc[y_disc == n_buckets] -= 1\n",
    "    return y_disc\n",
    "    \n",
    "y_delta_buckets = 9\n",
    "def batch_to_numpy(batch):\n",
    "    x = 2.* batch['image'] / 255. - 1 \n",
    "    y_abs = batch['steering_abs']\n",
    "    y_delta = get_steering_delta(batch)\n",
    "    y_delta_disc = discretize(y_delta / np.pi * 180, n_buckets=y_delta_buckets, min=-45, max=45)\n",
    "    return x[:,:,:,np.newaxis],  get_steering_hist(batch), y_delta_disc, y_abs\n",
    "\n",
    "X, s_hist, y_delta, y_abs = batch_to_numpy(batch_aug)\n",
    "print(\"data: {}, y_delta: {}, y_abs: {}\".format(X.shape, y_delta.shape, y_abs.shape))\n",
    "print(\"data max: {}, data min: {}\".format(X.max(), X.min()))\n",
    "print(\"y_delta max: {}, y_delta min: {}\".format(y_delta.max(), y_delta.min()))\n",
    "print(\"y_abs max: {}, y_abs min: {}\".format(y_abs.max(), y_abs.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def continuous(y, n_buckets, min, max):\n",
    "    y_norm = y / n_buckets\n",
    "    y = y_norm * (max - min) + min + (max-min) / (2 *n_buckets)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = discretize(np.linspace(delta_discretize_min, delta_discretize_max, num=90),\n",
    "                  delta_discretize_buckets, min=delta_discretize_min, max=delta_discretize_max)\n",
    "cont = continuous(disc, delta_discretize_buckets, min=delta_discretize_min, max=delta_discretize_max)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "ax[0].hist(disc, bins=9)\n",
    "_ = ax[1].hist(cont, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_p_x(x, pi_logits, means, s, delta = np.pi / (2*180), min=-np.pi/2, max=np.pi/2):\n",
    "    \"\"\"\n",
    "    bs - batch_size\n",
    "    w - width\n",
    "    k - number of components\n",
    "    \n",
    "    x: (bs, w, 1)\n",
    "    mu, s, pi_logits: (bs, w, k)\n",
    "    \"\"\"\n",
    "\n",
    "    # rv = tf.contrib.distributions.Logistic(means, s)\n",
    "    cdf = lambda t: tf.nn.sigmoid((t - means) / s)   \n",
    "    p = cdf(x + delta) - cdf(x - delta)\n",
    "    p_bar = p\n",
    "    k = pi_logits.get_shape()[-1]\n",
    "    x = tf.tile(x, [1, 1, int(k)])\n",
    "    p = tf.where(\n",
    "        x - delta <= min, \n",
    "        cdf(min),\n",
    "        p,\n",
    "    )\n",
    "    p = tf.where(\n",
    "        x + delta >= max,\n",
    "        1. - cdf(max),\n",
    "        p,\n",
    "    )\n",
    "    return tf.reduce_logsumexp(tf.nn.log_softmax(pi_logits) + tf.log(tf.maximum(p, 1e-12)), axis=-1)\n",
    "\n",
    "def log_p_x_pdf(x, pi_logits, means, s):\n",
    "    rv = tf.contrib.distributions.Logistic(means, s)\n",
    "    p = rv.prob(x)\n",
    "    return tf.reduce_logsumexp(tf.nn.log_softmax(pi_logits) + tf.log(tf.maximum(p, 1e-12)), axis=-1)\n",
    "\n",
    "def discretize_mixture(pi_logits, means, s, min=-np.pi/2, max=np.pi/2, num=180):\n",
    "    x = tf.linspace(min, max, num)\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    bs = means.shape[0]\n",
    "    x = tf.tile(x, [tf.shape(means)[0], 1])\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    \n",
    "    pi_logits = tf.tile(pi_logits, [1, num, 1])\n",
    "    means = tf.tile(means, [1, num, 1])\n",
    "    s = tf.tile(s, [1, num, 1])\n",
    "    return log_p_x(\n",
    "        x, pi_logits, means, s, min=min, max=max\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_mixtures = 6\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "len_steering_hist = get_steering_hist(batch).shape[-1]\n",
    "len_steering_delta = get_steering_delta(batch).shape[-1]\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, crop_size[1], crop_size[0], 1], name='image')\n",
    "steering_hist = tf.placeholder(tf.float32, shape=[None, len_steering_hist], name='steering_hist')\n",
    "\n",
    "y_abs_true = tf.placeholder(tf.float32, shape=[None, 1], name='y_abs_true')\n",
    "y_delta_true = tf.placeholder(tf.int32, shape=[None, len_steering_delta], name='y_delta_true')\n",
    "y_delta_true_hot = tf.one_hot(y_delta_true, depth=y_delta_buckets)\n",
    "\n",
    "f = 12\n",
    "k = 3\n",
    "\n",
    "\n",
    "# data images are 48x64\n",
    "\n",
    "l = tf.layers.conv2d(x,f, 5, padding='same')\n",
    "l = tf.layers.batch_normalization(l)\n",
    "l = tf.nn.relu(l)\n",
    "l = tf.layers.max_pooling2d(l, 2, 2)\n",
    "\n",
    "# 24x32 after pooling\n",
    "l = tf.layers.conv2d(x,2*f, k, padding='same')\n",
    "l = tf.layers.batch_normalization(l)\n",
    "l = tf.nn.relu(l)\n",
    "l = tf.layers.max_pooling2d(l, 2, 2)\n",
    "\n",
    "# 12x16\n",
    "l = tf.layers.conv2d(x,4*f, k, padding='same')\n",
    "l = tf.layers.batch_normalization(l)\n",
    "l = tf.nn.relu(l)\n",
    "l = tf.layers.max_pooling2d(l, (2,2), 2)\n",
    "\n",
    "# 6x8\n",
    "l = tf.layers.conv2d(x,8*f, k, padding='same')\n",
    "l = tf.layers.batch_normalization(l)\n",
    "l = tf.nn.relu(l)\n",
    "l = tf.layers.average_pooling2d(l,(6,8),1)\n",
    "l = tf.contrib.layers.flatten(l)\n",
    "l = tf.concat([l, steering_hist], axis=-1)\n",
    "l = tf.layers.dense(l, 4*f)\n",
    "l = tf.layers.batch_normalization(l)\n",
    "l = tf.nn.relu(l)\n",
    "\n",
    "mu = np.pi * tf.tanh(tf.layers.dense(l, n_mixtures))\n",
    "pi_logits = tf.layers.dense(l, n_mixtures)\n",
    "s = tf.nn.softplus(tf.layers.dense(l, n_mixtures))\n",
    "\n",
    "mu = tf.expand_dims(mu, axis=1)\n",
    "pi_logits = tf.expand_dims(pi_logits, axis=1)\n",
    "s = tf.expand_dims(s, axis=1)\n",
    "\n",
    "\n",
    "y_delta_logits = tf.layers.dense(l, len_steering_delta * y_delta_buckets)\n",
    "y_delta_logits = tf.reshape(y_delta_logits, (-1, len_steering_delta, y_delta_buckets))\n",
    "y_delta_prob = tf.nn.softmax(y_delta_logits)\n",
    "\n",
    "y_delta_loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=y_delta_true_hot, logits=y_delta_logits)\n",
    "y_abs_loss = -log_p_x(tf.expand_dims(y_abs_true, axis=1), pi_logits, mu, s)\n",
    "\n",
    "y_abs_discr_prob = discretize_mixture(pi_logits, mu, s)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.0003)\n",
    "opt_op = opt.minimize(y_delta_loss + y_abs_loss)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "history = {'y_delta': [], 'y_abs': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, = sess.run([y_abs_discr_prob], feed_dict={x: X, steering_hist: s_hist})\n",
    "print(probs.shape)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(np.arange(180) - 90, np.exp(probs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, s_hist, y_delta_, y_abs_ = batch_to_numpy(augment_batch(batch))\n",
    "dropout = np.random.binomial(1, 0.75, s_hist.shape)\n",
    "s_hist = dropout * s_hist\n",
    "dropout = np.random.binomial(1, 0.85, (s_hist.shape[0], 1))\n",
    "s_hist = np.tile(dropout, (1, 4)) * s_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tqdm_gen = tqdm(data_generator(batch_size=256, n_epoch=40))\n",
    "running_loss = 'init'\n",
    "for batch in tqdm_gen:\n",
    "    X, s_hist, y_delta_, y_abs_ = batch_to_numpy(augment_batch(batch))\n",
    "    # y += np.random.normal(0, 0.005 * np.pi, y.shape)\n",
    "    # y = np.clip(y, -np.pi / 2, np.pi / 2)\n",
    "    dropout = np.random.binomial(1, 0.75, s_hist.shape)\n",
    "    s_hist = dropout * s_hist\n",
    "    dropout = np.random.binomial(1, 0.85, (s_hist.shape[0], 1))\n",
    "    s_hist = np.tile(dropout, (1, 4)) * s_hist\n",
    "    \n",
    "    y_delta_loss_, y_abs_loss_, _ = sess.run([y_delta_loss, y_abs_loss, opt_op], feed_dict={\n",
    "        x:X, steering_hist: s_hist,\n",
    "        y_abs_true: y_abs_, y_delta_true: y_delta_})\n",
    "    \n",
    "    \n",
    "    history['y_delta'].append(np.mean(y_delta_loss_))\n",
    "    history['y_abs'].append(np.mean(y_abs_loss_))\n",
    "    batch_loss = np.mean(y_delta_loss_) + np.mean(y_abs_loss_)\n",
    "    if running_loss == 'init':\n",
    "        running_loss = batch_loss\n",
    "    else:\n",
    "        running_loss = 0.9*running_loss + 0.1*batch_loss\n",
    "    tqdm_gen.set_description('loss: {:.02f}'.format(running_loss))\n",
    "    \n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, os.path.join(model_dir, model_name + \".ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['y_delta'])\n",
    "for name in history.keys():\n",
    "    plt.plot(history[name], label=name)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, y_delta_prob_ = sess.run([y_abs_discr_prob, y_delta_prob], feed_dict={x: X, steering_hist: s_hist})\n",
    "print(probs.shape)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(15, 10))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.bar(np.arange(180) - 90, np.exp(probs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 10\n",
    "cols = y_delta_prob_.shape[1]\n",
    "bins = y_delta_prob_.shape[2]\n",
    "fig, axes = plt.subplots(rows, cols+2, figsize=(2*cols, rows))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols+2):\n",
    "        ax = axes[i, j]\n",
    "        if j == 0:\n",
    "            ax.imshow(X[i, :, :, 0], cmap='gray')\n",
    "            continue\n",
    "        if j == 1:\n",
    "            ax.bar(np.arange(180) - 90, np.exp(probs[i]))\n",
    "            continue\n",
    "            \n",
    "        j = j - 2\n",
    "        ax.bar(np.arange(bins), y_delta_prob_[i, j])\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_draw_info(img, steering_true, steering_pred, font=None):\n",
    "    scale = 30\n",
    "    pred_max = max(steering_pred)\n",
    "    steering_pred = np.array([xi/pred_max * scale for xi in steering_pred])\n",
    "    if font is None:\n",
    "        fonts = matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "        mono_fonts = [f for f in fonts if \"mono\" in f.lower() and 'bold' in f.lower()]\n",
    "        mono_font = mono_fonts[0]\n",
    "        font = ImageFont.truetype(mono_font, 18)\n",
    "    \n",
    "    \n",
    "    img = img.resize((640,480))\n",
    "    img= img.convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    \n",
    "    angle = steering_true + np.pi/2\n",
    "    x = 1/2 * img.size[0]\n",
    "    y = 90\n",
    "    x_start = x - 200\n",
    "    \n",
    "    legend_color = \"#ff0000\"\n",
    "    pred_color = \"#0099ffaa\"\n",
    "    draw.text((10,10), \"real:{}\".format(steering_true), fill=\"#00ff00ff\", font=font)\n",
    "    draw.text(\n",
    "        (img.size[0] - 300,10), \n",
    "        \"best predict:{}-> {:.2f}\".format(np.argmax(steering_pred) - 90,max(steering_pred)), \n",
    "        fill=pred_color,\n",
    "        font=font\n",
    "    )\n",
    "    \n",
    "    draw.text((x_start-5, y+10), \"-90\", fill=legend_color, font=font)\n",
    "    draw.text((x-5, y+10), \"0\", fill=legend_color, font=font)\n",
    "    draw.text((x-5+ 180, y+10), \"90\", fill=legend_color, font=font)\n",
    "    for i,prob in enumerate(steering_pred):\n",
    "        draw.line([x+2*(i-90), y, x+2*(i-90), y-prob], fill=pred_color, width=2)\n",
    "    \n",
    "    draw.line([x+2*steering_true, y, x+2*steering_true, y - scale], fill=\"#00ff00ff\", width=2)                       \n",
    "    del draw\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_stream = data_generator(batch_size=100, n_epoch=1, shuffle=False, train=False)\n",
    "_ = next(data_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fnames = []\n",
    "video_dir = tempfile.mkdtemp(dir=tmp_dir)\n",
    "print(video_dir)\n",
    "idx = 0\n",
    "for batch in tqdm(data_stream):\n",
    "    X, s_hist, y_delta_, y_abs_ = batch_to_numpy(batch)\n",
    "    X = X[:, 6:-6, 8:-8, :]\n",
    "    probs, y_delta_prob_ = sess.run([y_abs_discr_prob, y_delta_prob], \n",
    "                                    feed_dict={x: X, steering_hist: s_hist})\n",
    "    for i in range(len(X)):\n",
    "        img = PIL.Image.fromarray((255*(X[i, :, :, 0]/2 + 0.5)).astype(np.uint8), 'L')\n",
    "        img = image_draw_info(img, y_abs_[i, 0]/np.pi * 180, np.exp(probs[i]))\n",
    "        img_fname = os.path.join(video_dir, \"{:06d}.png\".format(idx))\n",
    "        img.save(img_fname)\n",
    "        idx += 1\n",
    "    \n",
    "    if idx > 500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(img, i):\n",
    "    img_fname = os.path.join(tmp_dir, \"{:06d}.png\".format(i))\n",
    "    img.save(img_fname)\n",
    "    \n",
    "try:\n",
    "    for i,test_pred,test_real, img in zip(range(len(predictions)), predictions, h5_file['steering'][:], h5_file['image'][:]):\n",
    "        img = PIL.Image.fromarray(img)\n",
    "        image_draw_info(img_scale, test_real, test_pred)\n",
    "        save_image(img_scale,i)\n",
    "        \n",
    "    video = ImageSequenceClip(tmp_dir, fps=24, with_mask=False)\n",
    "    video.write_videofile(\"test_set_evaluation.webm\", ffmpeg_params=['-b:v', '0', '-crf', '20'])\n",
    "finally:        \n",
    "    shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
